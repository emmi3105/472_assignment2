---
title: "Assignment 2"
author: "201903536"
date: "02 November 2023"
output: html_document
---

```{r setup, include=FALSE} 
#####################################
# SETUP
#####################################

knitr::opts_chunk$set(echo = FALSE) 

#####################################
# Install/load packages
#####################################

library(readr)
library(tidyverse)
library(countrycode)
library(quanteda)
library(quanteda.textplots)
library(ggplot2)
library(reshape2)
```



## Exercise 1

### Task: 
Simulate a version control workflow using git and GitHub.

My public GitHub repository with the solution to this exercise can be found [here](https://github.com/emmi3105/472_assignment2_ex1).



## Exercise 2

### Task: 
Generate a ggplot2 visualisation that answers the following question:

"To what extent did different regions of the world implement some form of recommendation or restriction for citizens to stay at home over the course of 2020-2022? How do the introduction of these restrictions compare to the regions’ implementation of income support over the same period?"



#### 1. Read in the data

```{r read in the data from GitHub, message=FALSE}

#####################################
# EXERCISE 2
#####################################
# Read in the data
#####################################

# Read in the data from GitHub and save it as cov_data
urlfile = "https://raw.githubusercontent.com/OxCGRT/covid-policy-dataset/main/data/OxCGRT_compact_national_v1.csv"
cov_data <- read_csv(url(urlfile))

```

First rows of the dataset:

```{r inspect the data, message=FALSE}
# Print the first rows of the dataset
print(head(cov_data))

```



#### 2. Clean the data

As of now, the dataset includes 56 variables, of which many are not of interest for the visualisation. Furthermore, the date variable is not formatted correctly. Also, the tasks requires us to group the countries into different regions. The dataset does include a variable indicating the country's region called RegionName. However, as seen in the first few rows of the dataset printed out above, the RegionName variable includes missing values, making it impossible to assign the observations to a specific region. Additionally, some of the column names such as "C6M_Stay at home requirements" include white space, which might lead to complications as R may not be able to handle these column names when using certain functions and packages in R.

Therefore, we need to clean the data before we can start with the visualisation. More precisely, we will 

- only select the variables that are needed for the plot so that we can decrease the size of the dataset that we are handling,
- format the date variable correctly so that it has the format Year-month-day,
- assign all observations to regions using the countrycode package,
- replace white space in column names,
- drop observations with missing values.


```{r clean the data}

#####################################
# Clean the data
#####################################

data_clean <- cov_data %>%
  # Select the variables of interest
  select(matches(c("CountryName", 
                   "RegionName", 
                   "C6M_Stay at home requirements", 
                   "E1_Income support", 
                   "Date"))) %>%
  # Format the date variable to Year-month-day
  mutate(Date = as.character(Date), 
         Date = ymd(Date)) %>%
  # Add region names using the countrycode package
  mutate(RegionName = countrycode(CountryName, "country.name", "region")) %>%
  # Replace white space in column names with underscores
  rename_all(~gsub("\\s", "_", .)) %>% 
  # Drop missing values
  drop_na()

```

Now, we have a dataset with 202'760 observations and 5 variables. 

1. CountryName indicating the name of the country

2. RegionName indicating the name of the region that the country was assigned to above. The regions are:

```{r unique values region}
# Print the unique values of the region name variable
print(unique(data_clean$RegionName))

```

3. C6M_Stay_at_home_requirements indicating whether the observation had some sort of stay at home requirement

This variable is categorical and can take the following values:

```{r unique values stay at home requirement}
# Check the values of the stay at home requirements variable
print(unique(data_clean$C6M_Stay_at_home_requirements))

```

According to the codebook in the repository (SOURCE), the categories mean the following:

- 0 - no measures
- 1 - recommend not leaving house
- 2 - require not leaving house with exceptions for daily exercise, grocery shopping, and 'essential' trips
- 3 - require not leaving house with minimal exceptions (eg allowed to leave once a week, or only one person can leave at a time, etc)
- Blank - no data

4. E1_Income_support indicating whether the observation received some sort of income support

Similarly to the stay at home requirement, this variable is also categorical and can take the following values:

```{r unique values income support}
# Check the values of the income support variable
print(unique(data_clean$E1_Income_support))

```

According to the codebook (SOURCE), the categories mean the following:

- 0 - no income support
- 1 - government is replacing less than 50% of lost salary (or if a flat sum, it is less than 50% median salary)
- 2 - government is replacing 50% or more of lost salary (or if a flat sum, it is greater than 50% median salary)
- Blank - no data

5. Date indicating the date in a Year-month-day format



#### 3. Prepare the data for plotting

We have cleaned and filtered the data for the variables of interest. However, the two variables indicating the stay at home requirements and the income support cannot be plotted as they are. The reason for that lies in the fact that the variables are categorical and nominal meaning that the values themselves are not meaningful in a quantitative way. If we were to plot nominal variables without any transformation, the visualisation would be misleading as it would seem as if the difference between the values that the nominal variable tells us something about the order of the variable although the difference itself is arbitrary. Hence, we will create binary variables that merely indicate whether there has been some sort of stay-at-home requirement or income support respectively thereby getting rid of other categories. 

The new variable "restriction_binary" takes a value of 1 if there has been some sort of stay at home restriction and 0 if no requirements at all have been enforced. The new variable "income_binary" takes a value of 1 if the government granted some sort of income support and 0 if no income support at all has been installed.

```{r create binary variables for stay at home requirement and income support}

#####################################
# Prepare the data for plotting
#####################################

# Create a binary variable indicating stay at home restrictions
data_clean$restriction_binary <- ifelse(data_clean$C6M_Stay_at_home_requirements == 1 | data_clean$C6M_Stay_at_home_requirements == 2 | data_clean$C6M_Stay_at_home_requirements == 3, 1, 0)

# Create a binary variable indicating income support
data_clean$income_binary <- ifelse(data_clean$E1_Income_support == 1 | data_clean$E1_Income_support == 2, 1, 0)

```


Lastly, we need the percentage of the observations for each region for which the binary variables above are 1. We do so by firstly grouping the data by region and then calculating the average for the restriction and income binaries by applying mutate() to the grouped data.

```{r group the plot data and calculate percentages}
# Group the dataframe and calculate the percentage
plot_data <- data_clean %>%
  group_by(RegionName, Date) %>%
  mutate(restriction_percentage = mean(restriction_binary) * 100) %>%
  mutate(income_percentage = mean(income_binary) * 100) %>%
  drop_na() %>%
  ungroup()

```



#### 4. Visualisation

```{r visualise the data, warning=FALSE, message=FALSE}

#####################################
# Create the visualisation
#####################################

my_plot <- ggplot(plot_data, aes(x = Date, group = RegionName)) +
  # Add a smooth line for the stay at home requirement percentage
  geom_smooth(aes(y = restriction_percentage, color = "Restriction"), 
              linetype = "solid", linewidth = 0.8) +
  # Add a smooth line for the income support percentag
  geom_smooth(aes(y = income_percentage, color = "Income"),
              linetype = "dashed", linewidth = 0.8) +
  # Add a title and axes labels
  labs(title = "Implementation of stay-at-home policies and income support per region, 2020-2022",
       x = "Date",
       y = "Percentage") + 
  # Set colors for the two binary variables and add a legend
  scale_color_manual(name = "Policy", values = c("#ff0066", "#33CCFF"), 
                     labels = c("Income Support", "Stay-at-home policies")) +
  # Add further elements such as the text size, line width, etc.
  theme_minimal() +
  scale_y_continuous(limits = c(0, 100), breaks = c(0, 50, 100)) +
  theme(plot.title = element_text(size = 12),
        axis.title = element_text(size = 10),
        axis.text = element_text(size = 8),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 8),
        legend.position = "bottom",
        strip.text.y = element_text(angle = 0),
        panel.spacing = unit(0.8, "lines"),
        legend.key.size = unit(0.8, "lines"))

# Adjust width and height as needed
options(repr.plot.width = 12, repr.plot.height = 8) 

# Add facets to the plot so that each region is represented in one facet
final_plot <- my_plot + facet_grid(rows = vars(RegionName))

# Print out the final plot
print(final_plot)

```

#### 5. Discussion of the visualisation

The visualisation above shows the percentage of countries in one region have implemented stay-at-home requirements and income support over the course of 2020-2022. This graph allows to analyse three elements. 

1. Firstly, it allows to compare the implementations of stay-at-home requirements to the implementation of income support in one region. For example, we can deduct that around May/June 2022- no countries in North America had implemented stay-at-home requirements, yet around 50% of North American countries granted income support of some sort. 
2. Secondly, the graph enables a comparison of policies across different regions. For example, we can see that around May/June 2022, North American countries had no policies requiring the people to stay at home. Yet, at the same time, around 30% - 40% of countries in the region East Asia & Pacific had some sort of stay-at-home requirements.
3. Lastly, the graph models the change of stay-at-home and income support policies across the time of 2020-2022. For instance, we can see that stay-at-home policies were started to become more prominent around May 2020 across most regions, which intuitively makes sense as the number of Covid cases started to pick up during this time globally (for more information on Covid cases across the different regions, refer to the [World Health organisation](https://covid19.who.int/)).

In the table below, it is summarised why certain graph features were chosen to enable the analyisis of the three elements listed above.


| Element | Explanation for the choice of graph features |
| -------------------------------------------- | -------------------------------------------- |
| Comparison of stay-at-home and income support policies | Due to the two policy variables originally being stored as categorical, nominal variables, merely plotting them as they were might lead to faulty interpretations as the size of the variables itself is meaningless - they simply represent a category. By transforming these two variables into binary variables and then calculating the mean allows to mitigate that issue. Now, the y-values on the graph simply represent how many countries from one regions have implemented some form of stay-at-home policy or income support at a certain point of time. This transformation also enables to compare the two variables in a useful way meaning that we can easily see when governments tried to mitigate the negative repercussions of stay-at-home requirements with income support. | 
| Comparison across regions | Plotting the seven regions in different facets makes the graph more readable since there only are two lines in one facets rather than having one plot with 14 lines. |
| Change of stay-at-home and income support implementations over time | In order to model the change of the binary variables over time, choosing the date variable for the x-axis is advisable. |


## Exercise 3

### Task 1:

Write three functions that transform strings according to a three different patterns using regular expressions.


#### Transformation a


Transformation pattern:
“apple” -> “pple” | “abacus” -> “bacus” | “Annapolis” -> “nnapolis”

We need to write a function that deletes the first character of the input string. Note that the function must be executable on lowercase strings as well as uppercase strings.

```{r regular expression string a, echo=TRUE}

#####################################
# EXERCISE 3 - Part 1
#####################################
# A
#####################################

# Write a function that deletes the first character of a string 
# using a regular expression

function_a <- function(astring) {
  # Deletes the first character of a string
  #
  # Inputs
  # astring: a string variable
  #
  # Output
  # returns the string without the first character
  
  new_string_a <- sub("^.([a-z])", "\\1", astring, ignore.case = TRUE)
  return(new_string_a)
}

# Test the function on the example strings
function_a("apple")
function_a("abacus")
function_a("Annapolis")

```


#### Transformation b


Transformation pattern:
“apple” -> “pple” | “abacus” -> “bcus” | “Annapolis” -> “Annpolis”

We need to write a function that deletes all lowercase "a" characters of the input string. Note that this time, the function should differentiate between lowercase and uppercase letters.

```{r regular expression string b, echo=TRUE}

#####################################
# B
#####################################

# Write a function that deletes all "a"s of a string 
# that are lowercase using a regular expression

function_b <- function(astring) {
  # Deletes the all lowercase "a" characters of a string
  #
  # Inputs
  # astring: a string variable
  #
  # Output
  # returns the string without all lowercase "a"s
  
  new_string_b <- gsub("a", "", astring, ignore.case = FALSE)
  return(new_string_b)
}

# Test the function on the example strings
function_b("apple")
function_b("abacus")
function_b("Annapolis")

```


#### Transformation c


Transformation pattern:
“C1_nat_a” -> “C_a” | “D2_state_g” -> “D_g” | “E_Loc_5_i” -> “E_i”

We need a function that returns the first character as well as the last two characters of the string. Note that in this particular exercise, the same result can be achieved in multiple ways. For instance, we could alternatively write a function that keeps the first and the last character of a string and separates them with an underscore. However, we will follow the first option.

```{r regular expression string c, echo=TRUE}

#####################################
# C
#####################################

# Write a function that returns the first character and the last two characters
# of a string using a regular expression

function_c <- function(astring) {
  # Deletes all characters but the first character and the last two characters of a string
  #
  # Inputs
  # astring: a string variable
  #
  # Output
  # returns the first character and the last two characters
  
  new_string_c <- sub("^(.).*(..)$", "\\1\\2", astring, ignore.case = TRUE)
  return(new_string_c)
}

# Test the function on the example strings
function_c("C1_nat_a")
function_c("D2_state_g")
function_c("E_Loc_5_i")

```




### Task 2:

Develop a research question that can be answered by counting how often certain words were mentioned in two books extracted from the [Gutenberg Project](https://www.gutenberg.org/) using a dictionary of words.


#### 1. Research question

For this task, the following research question should be answered:

**Which fairytale figures are the most prominenet ones in German compared to English fairytales?**

In order to answer this question, two collections of fairytales are downloaded from the Gutenberg Project:

1. [Grimm's fairy tales (German)](https://www.gutenberg.org/ebooks/2591)
2. [English fairy tales](https://gutenberg.org/ebooks/7439)

I used ChatGPT to configure ten different types of popular fairytale creatures and came up with the following list:

- Dragon
- Dwarf  
- Elf
- Fairy
- Giant
- Prince
- Princess
- Troll
- Witch 
- Wizard

We can now count the number of times these ten fairytale figures were mentioned in the collections of German and English fairytales in order to compare whether the two countries potentially have preferences for different fairytale figures.


#### 2. Select and download the books

Firstly, I downloaded the two fairytale collections mentioned above as .txt files and read them into R. The code chunk for this step can be seen in the Appendix.

```{r read in the books}

#####################################
# EXERCISE 3 - Part 2
#####################################

# Read the texts from the files
grimm_book <- read_file("grimm_fairy_tales.txt")
english_book <- read_file("english_fairy_tales.txt")

fairy_documents <- c(grimm_book, english_book)
names(fairy_documents) <- c("Grimm's Fairy Tales", "English Fairy Tales")

```

#### 3. Build a corpus from the two books

Then, I created a `corpus` object from the two texts using the `quanteda` package. This allowed me to not only store the content of the two books but to also store the names of each book under a so called document variable (`docvars`). I also stored the number of characters as document variables as the varying length of the two texts might explain why one book potentially holds more overall mentions of fairytale creatures than the other. The `docvars` are printed out below.

```{r create a corpus}
# Create a corpus
fairy_corpus <- corpus(fairy_documents,
                           docvars = data.frame(name = names(fairy_documents),
                                                characters = str_count(fairy_documents))
                           )

# Print out the document variables
docvars(fairy_corpus)

```
As we can see above, the English fairytale book is significantly shorter than the German one. Hence, we could expect that the mentions of fairytale creatures is generally higher in "Grimm's Fairy Tales". Let's find out whether our expectations are met.


#### 4. Build a dictionary and use it to count the mentions of fairytale creaturs

Based on ChatGPT's suggestions, I built a dictionary holding ten prevalent types of fairytale creatures. I made the simplification of only considering the noun in its singular and plural form and neglecting other forms using pre- or suffixes. . The dictionary is printed out below.


```{r create a dictionary}
# Create a dictionary based on ChatGPT fairytale creature suggestions
fairy_dict <- dictionary(list(dragon = c("dragon", "dragons"),
                              dwarf = c("dwarf", "dwarves"), 
                              elf = c("elf", "elves"), 
                              fairy = c("fairy", "faries"),
                              giant = c("giant", "giants"),
                              prince = c("prince", "princes"),
                              princess = c("princess", "princesses"),
                              troll = c("troll", "trolls"),
                              witch = c("witch", "witches"),
                              wizard = c("wizard", "wizards")
                               ))
fairy_dict

```
Using the `tokens()` function and the corpus created in the previous step, I create a document-feature matric (dfm). The rows of the dfm represent each of the two books and the columns show all words included in the books. The cells show the word counts in the respective book.

```{r create a document-feature matrix}
# Convert the corpus to tokens
fairy_tokens <- tokens(fairy_corpus)

# Convert the tokens to a document-feature matrix (dfm)
fairy_dfm <- dfm(fairy_tokens)

```

The dfm can now be used to count the mentions of the different fairytale figures. Using the function dfm_lookup(), I check how many times the words in the dictionary were mentioned in the two books. The results are printed out below.

```{r}
dfm_dictionary <- dfm_lookup(fairy_dfm, dictionary = fairy_dict,
                               valuetype = "glob") 
dfm_dictionary

```

#### 5. Discussion of the findings

As seen in the results printed out above, there are quite large differences between the times that different creatures have been mentioned in the two fairytale books. Not only do the creatures seem to vary in popularity - as for instance seen in comparing the mentions of princesses versus the mentions of trolls - but the two books seem to have different preferences for fairytale figures. In German fairytales, princesses, princes and dwarfs are the most prominent figures, whilst English books on the contrary seem to have a strong preference for giants. In the ggplot below, these findings are visualised.


```{r visualisation of the results}
# Convert the dfm to a dataframe
df <- convert(dfm_dictionary, to = "data.frame")

# Melt the dataframe for better visualization
df_melted <- melt(df, id.vars = "doc_id")

# Create the ggplot
ggplot(df_melted, aes(x = variable, y = value, fill = doc_id)) +
  geom_bar(stat = "identity", position = "dodge") +
  # Add a title and axes labels
  labs(title = "Count of Fairytale Figures in English and German Fairy Tale Collections",
       x = "Fairytale Figures",
       y = "Count", 
       fill = "Books") +
  theme_minimal() +
  scale_color_manual(name = "Book", values = c("#ff0066", "#33CCFF"), 
                     labels = c("English Fairy Tales", "Grimm's Fairy Tales")) +
  theme(plot.title = element_text(size = 12),
      axis.title = element_text(size = 12),
      axis.text = element_text(size = 10),
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 10),
      legend.position = "bottom",
      legend.key.size = unit(0.8, "lines")) +
  theme(axis.title.x = element_text(margin = margin(t = 10)),
        axis.title.y = element_text(margin = margin(r = 10)))

```

Lastly, it should be stressed that my basic analysis of the popularity of fairytale creatures is flawed. Firstly, there are mistakes in counting the instances, such as the neglection of the word "fairy" in the context of the story type "fairy tale" rather than the figure of a fairy itself. Secondly, it should be noted that the Grimm stories were translated from German into English, which might have led to faulty translations. For instance, there are several German words that can be translated as "wizard" - such as "Hexer" and "Zauberer" - yet might have been translated as "sorcerer" or some other synonymous term. This might explain why the term "wizard" was not mentioned at all in Grimm's Fairy Tales even though some of the stories might have included a wizard. Furthermore, neither the dictionary nor the book examples are finite lists making it impossible to formulate generalising conclusions on the preferences for some fairytale figures over others in different countries.


## Sources

[1] Horst, A., Hill, A., and Gorman, K. (2020). "palmerpenguins: Palmer Archipelago (Antarctica) penguin data." R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.

[2] Hale, T., Angrist, N., Goldszmidt, R., Kira, B., Petherick, A., Phillips, T., Webster, S., Cameron-Blake, E., Hallas, L., Majumdar, S., and Tatlow, H. (2021). "A global panel database of pandemic policies (Oxford COVID-19 Government Response Tracker)." Nature Human Behaviour. doi: 10.1038/s41562-021-01079-8

[3a] Grimm, J. and Grimm, W. (Uploaded 2001). "Grimms' Fairy Tales." Project Gutenberg. Retrieved from https://www.gutenberg.org/ebooks/2591

[3b] Jacobs, J. (Uploaded 2005). "English Fairy Tales." Project Gutenberg. Retrieved from https://gutenberg.org/ebooks/7439




## Appendix: All code in this assignment

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 


```
