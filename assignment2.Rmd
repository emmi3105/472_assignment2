---
title: "Assignment 2"
author: "201903536"
date: "02 November 2023"
output: html_document
---

```{r setup, include=FALSE} 
#####################################
# SETUP
#####################################

knitr::opts_chunk$set(echo = FALSE) 

#####################################
# Install/load packages
#####################################

library(readr)
library(tidyverse)
library(countrycode)
library(quanteda)
library(quanteda.textplots)
```



## Exercise 1

### Task: 
Simulate a version control workflow using git and GitHub.

My public GitHub repository with the solution to this exercise can be found [here](https://github.com/emmi3105/472_assignment2_ex1).



## Exercise 2

### Task: 
Generate a ggplot2 visualisation that answers the following question:

"To what extent did different regions of the world implement some form of recommendation or restriction for citizens to stay at home over the course of 2020-2022? How do the introduction of these restrictions compare to the regions’ implementation of income support over the same period?"



#### 1. Read in the data

```{r read in the data from GitHub, message=FALSE}

#####################################
# EXERCISE 2
#####################################
# Read in the data
#####################################

# Read in the data from GitHub and save it as cov_data
urlfile = "https://raw.githubusercontent.com/OxCGRT/covid-policy-dataset/main/data/OxCGRT_compact_national_v1.csv"
cov_data <- read_csv(url(urlfile))

```

First rows of the dataset:

```{r inspect the data, message=FALSE}
# Print the first rows of the dataset
print(head(cov_data))

```



#### 2. Clean the data

As of now, the dataset includes 56 variables, of which many are not of interest for the visualisation. Furthermore, the date variable is not formatted correctly. Also, the tasks requires us to group the countries into different regions. The dataset does include a variable indicating the country's region called RegionName. However, as seen in the first few rows of the dataset printed out above, the RegionName variable includes missing values, making it impossible to assign the observations to a specific region. Additionally, some of the column names such as "C6M_Stay at home requirements" include white space, which might lead to complications as R may not be able to handle these column names when using certain functions and packages in R.

Therefore, we need to clean the data before we can start with the visualisation. More precisely, we will 

- only select the variables that are needed for the plot so that we can decrease the size of the dataset that we are handling,
- format the date variable correctly so that it has the format Year-month-day,
- assign all observations to regions using the countrycode package,
- replace white space in column names,
- drop observations with missing values.


```{r clean the data}

#####################################
# Clean the data
#####################################

data_clean <- cov_data %>%
  # Select the variables of interest
  select(matches(c("CountryName", 
                   "RegionName", 
                   "C6M_Stay at home requirements", 
                   "E1_Income support", 
                   "Date"))) %>%
  # Format the date variable to Year-month-day
  mutate(Date = as.character(Date), 
         Date = ymd(Date)) %>%
  # Add region names using the countrycode package
  mutate(RegionName = countrycode(CountryName, "country.name", "region")) %>%
  # Replace white space in column names with underscores
  rename_all(~gsub("\\s", "_", .)) %>% 
  # Drop missing values
  drop_na()

```

Now, we have a dataset with 202'760 observations and 6 variables. 

1. CountryName indicating the name of the country

2. RegionName indicating the name of the region that the country was assigned to above. The regions are:

```{r unique values region}
# Print the unique values of the region name variable
print(unique(data_clean$RegionName))

```

3. C6M_Stay_at_home_requirements indicating whether the observation had some sort of stay at home requirement

This variable is categorical and can take the following values:

```{r unique values stay at home requirement}
# Check the values of the stay at home requirements variable
print(unique(data_clean$C6M_Stay_at_home_requirements))

```

According to the codebook in the repository (SOURCE), the categories mean the following:

- 0 - no measures
- 1 - recommend not leaving house
- 2 - require not leaving house with exceptions for daily exercise, grocery shopping, and 'essential' trips
- 3 - require not leaving house with minimal exceptions (eg allowed to leave once a week, or only one person can leave at a time, etc)
- Blank - no data

4. E1_Income_support indicating whether the observation received some sort of income support

Similarly to the stay at home requirement, this variable is also categorical and can take the following values:

```{r unique values income support}
# Check the values of the income support variable
print(unique(data_clean$E1_Income_support))

```

According to the codebook (SOURCE), the categories mean the following:

- 0 - no income support
- 1 - government is replacing less than 50% of lost salary (or if a flat sum, it is less than 50% median salary)
- 2 - government is replacing 50% or more of lost salary (or if a flat sum, it is greater than 50% median salary)
- Blank - no data

5. Date indicating the date in a Year-month-day format



#### 3. Prepare the data for plotting

We have cleaned and filtered the data for the variables of interest. However, the two variables indicating the stay at home requirements and the income support cannot be plotted as they are. The reason for that lies in the fact that the variables are categorical and nominal meaning that the values themselves are not meaningful in a quantitative way. If we were to plot nominal variables without any transformation, the visualisation would be misleading as it would seem as if the difference between the values that the nominal variable tells us something about the order of the variable although the difference itself is arbitrary. Hence, we will create binary variables that merely indicate whether there has been some sort of stay-at-home requirement or income support respectively thereby getting rid of other categories. 

The new variable "restriction_binary" takes a value of 1 if there has been some sort of stay at home restriction and 0 if no requirements at all have been enforced. The new variable "income_binary" takes a value of 1 if the government granted some sort of income support and 0 if no income support at all has been installed.

```{r creare binary variables for stay at home requirement and income support}

#####################################
# Prepare the data for plotting
#####################################

# Create a binary variable indicating stay at home restrictions
data_clean$restriction_binary <- ifelse(data_clean$C6M_Stay_at_home_requirements == 1 | data_clean$C6M_Stay_at_home_requirements == 2 | data_clean$C6M_Stay_at_home_requirements == 3, 1, 0)

# Create a binary variable indicating income support
data_clean$income_binary <- ifelse(data_clean$E1_Income_support == 1 | data_clean$E1_Income_support == 2, 1, 0)

```


Lastly, the data needs to be grouped. Furthermore we need the percentage of the observations for each region for which the binary variables above are 1.


```{r group the plot data and calculate percentages}
# Group the dataframe and calculate the percentage
plot_data <- data_clean %>%
  filter(Date<as.Date("2023-01-01")) %>%
  group_by(RegionName, Date) %>%
  mutate(restriction_percentage = mean(restriction_binary) * 100) %>%
  mutate(income_percentage = mean(income_binary) * 100) %>%
  drop_na() %>%
  ungroup()

```



#### 4. Visualisation

```{r, warning=FALSE, message=FALSE}

#####################################
# Create the visualisation
#####################################

my_plot <- ggplot(plot_data, aes(x = Date, group = RegionName)) +
  geom_smooth(aes(y = restriction_percentage, color = "Restriction"), 
              linetype = "solid", linewidth = 0.8) +
  geom_smooth(aes(y = income_percentage, color = "Income"),
              linetype = "dashed", linewidth = 0.8) +
  labs(title = "Implementation of stay-at-home policies and income support per region, 2020-2022",
       x = "Date",
       y = "Percentage",
       color = "Region") +
  scale_color_manual(name = "Policy", values = c("#ff0066", "#33CCFF"), 
                     labels = c("Income Support", "Stay-at-home policies")) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 100), breaks = c(0, 50, 100)) +
  theme(plot.title = element_text(size = 12),
        axis.title = element_text(size = 10),
        axis.text = element_text(size = 8),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 8),
        legend.position = "bottom",
        strip.text.y = element_text(angle = 0),
        panel.spacing = unit(0.8, "lines"),
        legend.key.size = unit(0.8, "lines"))

# Adjust width and height as needed
options(repr.plot.width = 12, repr.plot.height = 8) 

# Add facets to the plot so that each region is represented in one facet
final_plot <- my_plot + facet_grid(rows = vars(RegionName))

print(final_plot)

```

+++ Add a paragraph explaining why I chose this particular visualisation type.



## Exercise 3

### Task 1:

Write three functions that transform strings according to a three different patterns using regular expressions.


#### Transformation a


Transformation pattern:
“apple” -> “pple” | “abacus” -> “bacus” | “Annapolis” -> “nnapolis”

We need to write a function that deletes the first character of the input string. Note that the function must be executable on lowercase strings as well as uppercase strings.

```{r regular expression string a, echo=TRUE}

#####################################
# EXERCISE 3
#####################################
# A
#####################################

# Write a function that deletes the first character of a string 
# using a regular expression

function_a <- function(astring) {
  # Deletes the first character of a string
  #
  # Inputs
  # astring: a string variable
  #
  # Output
  # returns the string without the first character
  
  new_string_a <- sub("^.([a-z])", "\\1", astring, ignore.case = TRUE)
  return(new_string_a)
}

# Test the function on the example strings
function_a("apple")
function_a("abacus")
function_a("Annapolis")

```


#### Transformation b


Transformation pattern:
“apple” -> “pple” | “abacus” -> “bcus” | “Annapolis” -> “Annpolis”

We need to write a function that deletes all lowercase "a" characters of the input string. Note that this time, the function should differentiate between lowercase and uppercase letters.

```{r regular expression string b, echo=TRUE}

#####################################
# B
#####################################

# Write a function that deletes all "a"s of a string 
# that are lowercase using a regular expression

function_b <- function(astring) {
  # Deletes the all lowercase "a" characters of a string
  #
  # Inputs
  # astring: a string variable
  #
  # Output
  # returns the string without all lowercase "a"s
  
  new_string_b <- gsub("a", "", astring, ignore.case = FALSE)
  return(new_string_b)
}

# Test the function on the example strings
function_b("apple")
function_b("abacus")
function_b("Annapolis")

```


#### Transformation c


Transformation pattern:
“C1_nat_a” -> “C_a” | “D2_state_g” -> “D_g” | “E_Loc_5_i” -> “E_i”

We need a function that returns the first character as well as the last two characters of the string. Note that in this particular exercise, the same result can be achieved in multiple ways. For instance, we could alternatively write a function that keeps the first and the last character of a string and separates them with an underscore. However, we will follow the first option.

```{r regular expression string c, echo=TRUE}

#####################################
# C
#####################################

# Write a function that returns the first character and the last two characters
# of a string using a regular expression

function_c <- function(astring) {
  # Deletes all characters but the first character and the last two characters of a string
  #
  # Inputs
  # astring: a string variable
  #
  # Output
  # returns the first character and the last two characters
  
  new_string_c <- sub("^(.).*(..)$", "\\1\\2", astring, ignore.case = TRUE)
  return(new_string_c)
}

# Test the function on the example strings
function_c("C1_nat_a")
function_c("D2_state_g")
function_c("E_Loc_5_i")

```




### Task 2:

The Gutenberg Project is an open library of over 70,000 books, accessible here [https://www.gutenberg.org/]. In this exercise, you will come up with a research question that can be answered by counting the incidences of dictionary terms across a selection of books downloaded from this website.

First, develop a simple research question that should seek to compare how often a given concept is mentioned across a selection books. An example research question might be: “How often are house pets mentioned in the works of Jane Austen?” Briefly introduce your question and define your concept. Your concept must be measurable using a dictionary of words. For example, if our concept is house pets, we could measure whether they are mentioned by checking for incidences of “dog”,“cat”, and “budgerigar”.

Next, select and download at least two books as .txt files books from the Gutenberg Project that you will use to answer your research question. Your choice of books should be relevant to your research question.

Using the quanteda package, build a corpus from your selected books (each document should be the entire book) and a dictionary that encodes your concept. Then, use your dictionary to count the incidences of your concept across these books.

Finally, discuss your findings and provide an answer to your research question.



#### 1. Research question

For this task, the following research question should be answered:

**How often are different fairytale figures mentioned in fairytale books from different countries?**

In order to answer this question, two collections of fairytales are downloaded from the Gutenberg Project:

1. [Grimm's fairy tales (German)](https://www.gutenberg.org/ebooks/2591)
2. [English fairy tales](https://gutenberg.org/ebooks/7439)

I used ChatGPT to configure ten different types of popular fairytale creatures and came up with the following list:

- Dragon
- Dwarf  
- Elf
- Fairy
- Giant
- Mermaid
- Prince
- Princess
- Troll
- Witch 

These ten types were then used to count the indices of fairytale creatures across the books.


#### 2. Select and download the books

Firstly, I downloaded the two fairytale collections mentioned above as .txt files and read them into R.

```{r read in the books}
# Read the texts from the files
grimm_book <- read_file("grimm_fairy_tales.txt")
english_book <- read_file("english_fairy_tales.txt")

fairy_documents <- c(grimm_book, english_book)
names(fairy_documents) <- c("Grimm's Fairy Tales", "English Fairy Tales")

```

#### 3. Build a corpus from the two books

Then, I created a `corpus` object from the two texts using the `quanteda` package. This allowed me to not only store the content of the two books but to also store the names of each book under a so called document variable (`docvars`). I also stored the number of characters as document variables as the varying length of the two texts might explain why one book potentially holds more overall mentions of fairytale creatures than the other.

```{r create a corpus}
# Create a corpus
fairy_corpus <- corpus(fairy_documents,
                           docvars = data.frame(name = names(fairy_documents),
                                                characters = str_count(fairy_documents))
                           )

# Print out the document variables
docvars(fairy_corpus)

```
As we can see above, the English fairytale book is significantly shorter than the German one. Hence, we could expect that the mentions of fairytale creatures is generally higher in "Grimm's Fairy Tales". Let's find out whether our expectations are met.


#### 4. Build a dictionary and use it to count the mentions of fairytale creaturs

Based on ChatGPT's suggestions, I built a dictionary holding ten prevalent types of fairytale creatures. I used regular expressions to make sure that varying spellings of the dictionary keys (for instance in case of plural words) will still be considered in the count.


```{r create a dictionary}
# Create a dictionary based on ChatGPT fairytale creature suggestions
fairy_dict <- dictionary(list(dragon = c("dragon", "dragons"),
                              dwarf = c("dwarf", "dwarves"), 
                              elf = c("elf", "elves"), 
                              fairy = c("fairy", "faries"),
                              giant = c("giant", "giants"),
                              prince = c("prince", "princes"),
                              princess = c("princess", "princesses"),
                              troll = c("troll", "trolls"),
                              witch = c("witch", "witches"),
                              wizard = c("wizard", "wizards")
                               ))
fairy_dict

```
Using the `tokens()` function and the corpus created in the previous step, I create a document-feature matric (dfm). The rows of the dfm represent each of the two books and the columns show all words included in the books. The cells show the word counts in the respective book. The first columns of the dfm are printed out below

```{r create a document-feature matrix}
# Convert the corpus to tokens
fairy_tokens <- tokens(fairy_corpus)

# Convert the tokens to a document-feature matrix (dfm)
fairy_dfm <- dfm(fairy_tokens)
fairy_dfm

```

For instance, the dfm shows that the word "tales" was mentioned 11 times in Grimm's Fairy Tales and 45 times in the English Fairy Tales. Using the function dfm_lookup(), I check how many times the words in the dictionary were mentioned in the two books. The results are printed out below.

```{r}
dfm_dictionary <- dfm_lookup(fairy_dfm, dictionary = fairy_dict,
                               valuetype = "glob") 
dfm_dictionary
```

#### 5. Discussion of the findings

As seen in the results printed out above, there are quite large differences between the times that different creatures have been mentioned in the two fairytale books. Not only do the creatures seem to vary in popularity - as for instance seen in comparing the mentions of princesses versus the mentions of trolls - but the two books seem to have different preferences for fairytale figures. In German fairytales, princesses, princes and dwarfs are the most prominent figures, whilst English books on the contrary seem to have a strong preference for giants. In the ggplot below, these findings are visualised.

```{r}
# Convert the dfm to a dataframe
df <- convert(dfm_dictionary, to = "data.frame")
df
```
```{r}
column_names <- colnames(df)[-1]
column_names
```


 

Lastly, it should be stressed that my basic analysis of the popularity of fairytale creatures is flawed. Firstly, there are mistakes in counting the instances, such as the neglection of the word "fairy" in the context of the story type "fairy tale" rather than the figure of a fairy itself. Secondly, it should be noted that the Grimm stories were translated from German into English, which might have led to faulty translations. For instance, there are several German words that can be translated as "wizard" - such as "Hexer" and "Zauberer" - yet might have been translated as "sorcerer" or some other synonymous term. This might explain why the term "wizard" was not mentioned at all in Grimm's Fairy Tales even though some of the stories might have included a wizard. Furthermore, neither the dictionary nor the book examples are finite lists making it impossible to formulate generalising conclusions on the preferences for some fairytale figures over others in different countries.

## Sources

[1] penguins data

[2] Thomas Hale, Noam Angrist, Rafael Goldszmidt, Beatriz Kira, Anna Petherick, Toby Phillips, Samuel Webster, Emily Cameron-Blake, Laura Hallas, Saptarshi Majumdar, and Helen Tatlow. (2021). “A global panel database of pandemic policies (Oxford COVID-19 Government Response Tracker).” Nature Human Behaviour. https://doi.org/10.1038/s41562-021-01079-8

[3] Fairytale books



## Appendix: All code in this assignment

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 


```
